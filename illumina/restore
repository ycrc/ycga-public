#!/usr/bin/env python3

from subprocess import Popen, PIPE
import tarfile, logging, threading, time, argparse, os, errno, glob

EPILOG='''This script provides a convenient way to unpack and decompress archived sequencer datasets to a scratch directory.  

Runs are archived as 1 or more tarballs.  There is a main tarball containing auxillary files as well as any undetermined sequences.  Then
there is one tarball per project that contains the actual sequencing data for the project.  Most users will only need the project tarball.

To find a run in the archive, you may find the utility locateRun useful:
$ locateRun <Pat>

e.g.
$ locateRun D09LVAC
/SAY/archive/YCGA-729009-YCGA/archive/ycga-ba/ba_sequencers3/sequencerV/runs/120120_SN827_0096_BD09LVACXX

$ ls -1 /SAY/archive/YCGA-729009-YCGA/archive/ycga-ba/ba_sequencers3/sequencerV/runs/120120_SN827_0096_BD09LVACXX
120120_SN827_0096_BD09LVACXX_0.tar
120120_SN827_0096_BD09LVACXX_1_Project_Mkc7.tar
120120_SN827_0096_BD09LVACXX_2016_05_23_20:03:21_archive.log
120120_SN827_0096_BD09LVACXX_2_Project_Mp686.tar
120120_SN827_0096_BD09LVACXX_3_Project_Ram98.tar
120120_SN827_0096_BD09LVACXX_4_Project_Skr2.tar
120120_SN827_0096_BD09LVACXX_5_Project_Bg292.tar
120120_SN827_0096_BD09LVACXX_6_Project_Vs236.tar
120120_SN827_0096_BD09LVACXX_finished.txt

To restore, for example, 120120_SN827_0096_BD09LVACXX_5_Project_Bg292.tar
$ cd ~/scratch60/mydata
$ restore -t /SAY/archive/YCGA-729009-YCGA/archive/ycga-ba/ba_sequencers3/sequencerV/runs/120120_SN827_0096_BD09LVACXX/120120_SN827_0096_BD09LVACXX_5_Project_Bg292.tar

By default:
  It will restore to the current directory.
  It will uncompress files.
  20 threads will be used for decompression.  You should execute this script on a compute node with the desired number 
    of cpus allocated for best decompression performance, e.g.:
    srun -c 20 bash

You can change the number of threads used for decompression using -n to restore, and -c to sbatch/srun.  If you run multiple threads, make sure to ask for more than the default
memory.

Note that the first step in the restore is to retrieve the tarball from the tape.  This can take several minutes, during which time nothing will appear to be happening.

A convenient way to restore a number of tarfiles is to create a file containing the names of tarfiles, one per line, and pass it to restore using -f.  
To uncompress multiple tarfiles listed in a file "tarfile.txt"
restore -f tarfile.txt

Contact robert.bjornson@yale.edu with questions or comments.

'''

class quipjob(threading.Thread):
    def __init__(self, tfname, qfname, dest):
        threading.Thread.__init__(self)
        self.tfname=tfname
        self.qfname=qfname
        self.dest=dest
        self.status=None

    def __str__(self):
        return "Quip Job "+self.qfname

    def run(self):
        self.status=doQuip(self.tfname, self.qfname, self.dest)


'''
Generic threaded job processor
'''
def processJobs(jobs, maxthds):

    pending=jobs
    running=[]
    done=[]
    currsum=0 # running total of estimate of memory needed by all running jobs.  We don't want to exceed o.maxsum

    while pending or running:
        # start as many jobs simultaneously as allowed by maxthds and maxsum
        while pending and len(running)<maxthds:
            job=pending.pop(0)
            job.starttime=time.time()
            logger.debug("starting job %s" % (job, ))
            job.start()
            running.append(job)

        # wait for the first job to finish and handle it
        waitjob=running.pop(0)
        waitjob.join()
        if waitjob.status:
            error("Job failed, terminating")

        logger.debug("job finished time %f: %s" % (time.time()-waitjob.starttime, waitjob))
        del waitjob


def mkdir_p(path):
    try:
        os.makedirs(path)
    except OSError as exc:  # Python >2.5
        if exc.errno == errno.EEXIST and os.path.isdir(path):
            pass
        else:
            raise

QUIP="/ycga-gpfs/apps/hpc/Tools/quip/1.1.8/bin/quip"
def doQuip(tfname, qfname, dest):
    logger.debug("doing %s" % qfname)
    pth=os.path.dirname(qfname)
    if not os.path.isdir(pth):
        logger.debug("making dir %s" % pth)
        mkdir_p(pth)
    newfn=qfname.replace(".qp", "")
    tarcmd=["tar", "-x", "-f", tfname, "-O", qfname]
    quipcmd=[QUIP, "-d", "-c", "-o", "fastq"]
    p1=Popen(tarcmd, stdout=PIPE)
    p2=Popen(quipcmd, stdin=p1.stdout, stdout=open(dest+'/'+newfn, 'w'))
    p1.stdout.close() # parent closes this.  This important so that P1 gets a sigpipe if P2 dies
    ret2=p2.wait()
    if ret2:
        logger.error("Error code %d from: %s" % (ret2, quipcmd))
    logger.debug("finished %s return val %d" % (newfn, ret2))
    return ret2

def doTarfile(tfname, dest):
    logger.info("Processing Tarfile %s" % tfname)
    if o.dryrun:
        return
    tf=tarfile.TarFile.open(tfname)
    qpjobs=[]
    nonqpfiles=[]
    for ti in tf:
        if ti.name.endswith(".qp") and not o.no_uncompress:
            qpjobs.append(quipjob(tfname, ti.name, dest))
        else:
            nonqpfiles.append(ti)
    tf.extractall(path=dest, members=nonqpfiles)
    logger.info("processing %d quip files" % len(qpjobs))
    processJobs(qpjobs, o.maxthds)

''' Utility error function.  Bomb out with an error message and code '''
def error(msg):
    logger.error(msg)
    raise RuntimeError(msg)

if __name__=='__main__':

    parser=argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, epilog=EPILOG)
    
    parser.add_argument("-t", "--tarfile", dest="tarfile",  help="tarfile or entire run to restore")
    parser.add_argument("-f", "--files", dest="tarfiles", help="file containing tarfiles or runs to restore")
    parser.add_argument("-d", "--destdir", dest="destdir", default=".", help="destination dir")
    parser.add_argument("-l", "--logfile", dest="logfile", default="restore", help="logfile prefix")
    parser.add_argument("--no_uncompress", dest="no_uncompress", action="store_true", default=False, help="leave compressed (quip) files as is")
    parser.add_argument("-v", "--verbose", dest="verbose", action="store_true", default=False, help="be verbose")
    parser.add_argument("-n", dest="maxthds", type=int, default=20, help="max threads")
    parser.add_argument("--dryrun", dest="dryrun", action="store_true", default=False, help="Don't do anything")

    o=parser.parse_args()
    starttime=time.time()

    # set up logger
    logger=logging.getLogger('restore')
    formatter=logging.Formatter("%(asctime)s %(threadName)s %(levelname)s %(message)s")
    logger.setLevel(logging.DEBUG)

    hc=logging.StreamHandler()
    hc.setFormatter(formatter)
    if not o.verbose: hc.setLevel(logging.INFO)
    logger.addHandler(hc)

    hf=logging.FileHandler("%s_%s.log" % (o.logfile, time.strftime("%Y_%m_%d_%H:%M:%S", time.gmtime())))
    hf.setFormatter(formatter)
    if not o.verbose: hf.setLevel(logging.DEBUG)
    logger.addHandler(hf)

    if o.tarfile and o.tarfiles:
        error("Please only specify one of -t -f")
    if not (o.tarfile or o.tarfiles):
        error("Please specify -t or -f")

    if o.tarfile:
        if os.path.isdir(o.tarfile):
            for tf in glob.glob(os.path.join(o.tarfile, "*.tar")):
                doTarfile(tf, o.destdir)
        else:
            doTarfile(o.tarfile, o.destdir)
    elif o.tarfiles:
        for tfname in open(o.tarfiles):
            tfname=tfname.strip()
            if os.path.isdir(tfname):
                for tf in glob.glob(os.path.join(tfname, "*.tar")):
                    doTarfile(tf.strip(), o.destdir)
            else:
                doTarfile(tfname.strip(), o.destdir)

    t = time.time() - starttime

    logger.info("Restore Finished %d sec" % t)
